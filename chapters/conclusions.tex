%!TEX root = ../main.tex

\chapter{Conclusions}\label{ch:conclusions}
This chapter concludes our work and this report by giving an overview of the achievements, including end-to-end results, and listing possible tasks for future work.

\section{Achievements}
In \autoref{sec:detection_results} we have analysed in-depth the results of various detection models. We proved that \FRCNN{} is able to learn handwriting-specific features and it can use them to detect handwritten text reasonably well. For our model, the confidence score of the detected boxes is less helpful for selecting high quality ones, but this is a \emph{small} problem since false positives can be filtered out at a later time. Alternatively, it is likely that fine tuning on a subset of \ds{Test} would aid the model to better distinguish between real text and text-like examples. Finally, we have seen that \CTPN{} is superior to most \FRCNN{} models, but the evaluation protocol we chose fails to capture this in numbers.

In a similar manner, \autoref{sec:transcription_results} proves that we found sensible alternatives to compensate for the lack of annotated data, but also that generated handwriting does not capture all the features of the real one. Our experiments identified several weaknesses of these approaches, and solved them one by one.

\section{End-to-end results}
With a candidate for each of the parts, we can now evaluate the final performance of our system, in a goal-directed fashion\footnote{The corpus type of a detection needed for the transcription module is that of the corresponding ground truth box.}. Pairing the best text transcription model, \ds{Gen_corpus_all}, with any of the detection models should objectively show which one is best, while also proving the capabilities achieved so far. Results are shown in \autoref{tab:e2e_results}. We see the \FRCNN{} model outperforms the \CTPN{} one but we have to re-state the caveat discussed in \autoref{sec:ctpn_results}: some correct \CTPN{} detections are merged into a single line thus being wrongly discarded due to low \(\iou\).

\begin{table}[htb]
\begin{tabular}{| l | *3{c |}}\hline
	\bf Model     & \bf CER & \bf WER & \(\mathbf{R}_{\iou = 0.5}\)\\\hline
	Best \FRCNN{} & 52.38   & 91.27   & 71\\
	Best \CTPN{}  & 53.73   & 90.87   & 54\\\hline
\end{tabular}
\caption{End-to-end results}\label{tab:e2e_results}
\end{table}

In conclusion, we developed a good handwriting detection system and we made major advances for the transcription one, establishing it into a proof of concept. The final results show that each can benefit from additional improvements before being ready to work together in a highly robust fashion.

\section{Future work}
There are many different paths to explore for any of the parts. For detection, we would like to investigate the influence of feature extractors, as well as training them from scratch. For the transcription part, we would like to test with much bigger generated datasets, with the mention that they should include more variation as well, i.e.\ a bigger vocabulary for the natural language corpus. Additionally, we could also test a deeper feature extractor here as well.

We would also like to point out the high similarity of LSTM mechanisms in \CTPN{} (detection) and \CRNN{} (transcription). This suggests that an end-to-end implementation is feasible, which is why we plan it as well for future work.

