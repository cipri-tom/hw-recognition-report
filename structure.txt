Introduction
	-- Motivation
		-- why do we do this
		-- how does the current process work
		-- how we envision it to work
		-- steps to get there
	-- Challenges
		-- restrictions imposed by data & process
		-- want to make it general (not specific to statement documents)
	-- Related work
		-- classical approaches
			-- detection -- bottom-up & top down; line detection (Hough); form processing
			-- recognition -- template matching, CRF, HMMs
		-- modern approaches
			-- detection -- CNNs, Max's work; other from ICLR, IHWR etc
			-- recognition -- MDLSTM, CRNN, Attention, embedding words & images in common subspace (needs dict)



================================================================================================



Detection -- v1
	-- Constraints + high_engineering_classical => need to use modern approach == CNNs + object detection
	-- Describe Faster R-CNN
		-- possible good description of CNNs: https://arxiv.org/pdf/1604.00187.pdf
		-- ... different parts ...
	-- FRCNN Experiments
		 § Generally, there's no data available -> We use external data and try to adapt it to improve quality of transfer. We use as database RIMES, b/c French and clean, but with problems which we will explore
		-- paragraph level -- side by side (2 or 3 way) -- doesn't generalize (mention gray vs B&W)
		-- noting sec:FRCNN_sampling => uses negative samples, so the above is too clean
			=> need have something that resembles the statement
			=> prepare templates and prefill with lines / words
		-- prefill with line: [DOESN'T WORK]
			-- too long, need to be split into tokens of several words
			++ use the same HW style for a continuous set of tokens => resembles real scenario
			-- must be careful not to cut a word => use horizontal projection and find white spaces
			-- doesn't work because there are badly segmented lines (including lines above, below)
			-- need to align to template => need to know baseline => baseline detection method
		-- prefill with words:
			-- too short => need to combine several => different HW style on same line
			-- but this could be good because we need to be robust to a high level of variation
			-- same baseline detection -- works well because words are better segmented (no skew or above/below text)
		-- TODO: prefill with Generator
	-- CTPN
		§ FRCNN can detect text, but with a generally poor accuracy -- no well centred
		§ could be solved, probably, with further bbox regression (as Jaderberg)
		§ but there's a better suited architecture --
		-- ... different parts ... and improvements (not all heights, no rotations)
	-- Results
		-- CTPN is better :)


Detection -- v2
	-- Object detection, general approach
	-- Faster R-CNN:
		-- Architecture
			-- ... different parts ...
		-- Results
			 § Generally, there's no data available -> We use external data and try to adapt it to improve quality of transfer. We use as database RIMES, b/c French and clean, but with problems which we will explore
			-- Data 1: full RIMES side-by-side => bad
			-- Data 2: Prefilled templates with RIMES => works, but meh
			-- Data 3: [NOT YET RUN] Prefilled templates with Word_Generator => should be better
		-- "Conclusions":
			-- can work, but often cuts text (show examples of IoU 0.5)
	-- CTPN (small boxes)
		-- improves on FRCNN weaknesses
		-- Architecture
			-- ...
		-- Results
			-- Data 2: decent, but not too tight boxes (noisy labels)
			-- Data 3: works well


================================================================================================

Recognition





================================================================================================



Results

================================================================================================


ABBREVIATIONS

OOV
CNN
RNN
LSTM
